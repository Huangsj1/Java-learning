# 一、虚拟内存空间

![[Pasted image 20240316114530.png]]

* 用户空间：`[0, 3GB)`，从下到上分为代码段、数据段、BSS段、堆、mmap段、栈
* 内核空间：`[3GB, 4GB)`，从下到上分为：直接映射区 `896MB`、动态内存映射区、永久内存映射区 `4MB`、固定内存映射区 `4MB`、临时内存映射区 `4KB`
	* ZONE_DMA + ZONE_NORMAL = 直接映射区
		* ZONE_DMA为16MB，因为ISA总线的DMA控制器只能对内存的前16MB进行寻址
	* ZONE_HIGHMEM高端内存区 = 动态内存映射区 + 永久内存映射区 + 固定内存映射区 + 临时内存映射区

## 1. 页表

内核虚拟地址直接放在了`[3GB, 4GB)`中，所有进程都共享这一块内核空间

* 内核有一个内核页表，负责映射内核到物理空间中
* 每个进程也有一个页表，创建进程的时候除了**对用户空间进行内存分配和映射**，还**拷贝了内核页表的映射**
	* 当**内核需要分配空间**时，是通过内核页表进行映射的，先不对进程页表的内核部分进行映射（延迟分配）；当进程进入内核态访问抛出页面异常时才将内核页表的映射拷贝到进程页表内核部分的映射

### 进程与线程

进程和线程用的都是 `task_struct` 结构，**创建进程和线程都会重新创建页表**，不过线程的页表中直接映射已有进程的sections、堆、mmap等共享资源，对于栈需要重新分配和映射

## 2. 用户虚拟空间

用户虚拟内存是通过在物理内存中分配来进行映射得到的

如果需要查找某块虚拟内存空间 `vm_area_struct`，通过链表需要 O(n)，于是可以通过构建红黑树以 O(logn) 来查找 `vm_area_struct`

![[Pasted image 20240316164057.png]]

## 3. 内核虚拟空间

![[Pasted image 20240316170845.png]]

### 1. 演变

* 最初物理内存不够的情况下，**内核可以在直接映射区中对其进行映射**（类似RunableOS中直接将内核sections和可分配的物理页面直接映射到内核空间中）
* 但是当物理内存逐渐扩大超过内核空间1GB的时候，如果还是**直接映射就会导致物理地址高内存部分内核无法访问**，所以需要在**内核中保留部分虚拟地址空间来动态分配进行物理高内存地址的映射**，这部分就是内核空间的 ZONE_HIGHMEM高端内存区
	* 访问地址需要经过MMU将虚拟地址转换成物理地址，如果要访问某块物理内存就**一定要在虚拟地址空间中有映射到物理地址的映射**（在RunableOS中内核虚拟地址空间对物理页帧进行了直接映射，所以可以直接通过对物理地址的访问来操作）

![[Pasted image 20240316115504.png|310]]![[Pasted image 20240316115526.png|310]]

### 2. 直接映射区

内核空间中的低 896MB 即 `[3GB, 3GB+896MB)`，直接映射到物理内存的 `[0, 896MB)`，这部分内存包括：

1. 内核的 `sections` 部分，包括内核的代码段、数据段、bss段
2. 剩余部分在使用的时候再分配物理内存进行映射（虽然也是间接映射，但是虚拟地址和物理地址有着对应关系）

* `kmalloc(size)` 在直接映射区分配物理内存并进行映射

### 3. 高端内存区

这一部分内存是通过**间接映射到物理内存的高内存空间**的

#### 1. 动态内存映射区

映射方式和用户态下的 `malloc()` 类似，通过在物理内存中分配页面映射到动态内存映射区中（虚拟地址连续，物理地址不一定连续）

* `vmalloc(size)` 分配内存并建立映射

#### 2. 永久内存映射区

用于为分配了连续物理页物理内存进行长期映射

* `alloc_page(mask, order)` 分配指定大小的物理页面 $2^{order}$ 页
* `kmap(page)` 将分配了的物理页面在永久内存映射区中进行连续映射

#### 3. 固定内存映射区

这里的虚拟地址在编译的时候就固定下来了，是在内核启动过程中被确定的，而这些虚拟地址对应的物理地址不是固定的

#### 4. 临时内存映射区

每个cpu有一块空间，每块空间都分为多个小空间（一页），每个小空间用于一个目的，可以进行临时的映射，会覆盖之前

# 二、物理内存管理

## 1. 物理页面管理

### 1. FLATMEM 平坦内存模型

直接通过结构数组来管理连续的物理内存

![[Pasted image 20240316173231.png]]

### 2. DISCONTIGMEM 非连续内存模型

如果物理内存是不连续的（由于NUMA存在，每个cpu只包含部分物理内存），通过平坦内存模型还需要为不存在的物理页帧分配对应的 `page` 结构来实现连续目的

可以通过分段保证每段连续来管理

![[Pasted image 20240316173451.png]]

### 3. SPARSEMEM 稀疏内存模型

但是 `node` 节点里面的连续物理页中可能有些物理页帧是空洞的（由于热拔插的存在，可以停止/开启某些物理页面），所以还需要更细粒度的划分

![[Pasted image 20240316174056.png]]

### 4. UMA和NUMA

#### 1. UMA

多个cpu共享整个物理内存

![[Pasted image 20240316174237.png]]

#### 4. NUMA

下面的每一个节点就是一个cpu管理的本地内存

![[Pasted image 20240316181742.png]]

每个节点的物理内存可以分为一下几个部分（每个部分从上面的 `plist_data`中分配页面）：

* `ZONE_DMA`：物理内存前16MB
* `ZONE_DMA32`：与ZONE_DMA类似，不过是给32位设备执行DMA用的
* `ZONE_NORMAL`：直接映射到节点的内核中的虚拟地址，线性映射
* `ZONE_HIGHMEM`：间接映射给节点的内核高端地址
* `ZONE_MOVABLE`：虚拟内存区域，可以将这里面的物理内存进行迁移来减少外部碎片
	* ![[Pasted image 20240316182504.png|400]]

![[Pasted image 20240316182021.png|400]]

`node_zones` 数组属于 `plist_data` 中的成员，其中每一个 `zone` 都有管理着自己的物理页框的伙伴系统

![[Pasted image 20240316182644.png]]

## 2. 物理页面分配

### 1. Buddy 伙伴算法

* 通过链表形式**将连续页面组成不同大小（2的n次幂）的空闲页块**来管理
* 如果当前队列中该大小的物理页块没有了，就将下一级的物理页块拆成两半给当前队列来进行分配

![[Pasted image 20240316214145.png]]

### 2. Slab算法

内核在使用对象的时候如果按照伙伴系统每次都要分配最小一页的内存，会**频繁执行 分配内存-初始化-释放内存**，消耗空间又耗时

Slab算法通过提前在内核中**为需要重复使用的内核对象提供slab缓冲池**，里面**存放了 已初始化 的对象**，当内核需要申请时slab直接提供即可

![[Pasted image 20240316215649.png]]

* `kmem_cache`：每个节点代表同一个类型的对象缓存
* `slabs_***`：链表管理着所有的 `slab` 节点
	* `slabs_full`：完全分配的 `slab` 链表（slab节点里面都分满了）
	* `slabs_partial`：分配了部分的 `slab` 链表
	* `slabs_empty`：空的 `slab` 链表
* `slab`：**slab分配器的基本单位**，包括一个或多个页面，里面可以分配一个或多个临时对象

![[Pasted image 20240316220621.png]]

### 3. 用户和内核的物理内存分配

* 用户最终会通过伙伴系统分配对应大小内存
* 内核如果分配内核对象会直接通过slab分配器来分配对象，所有的内存分配最终都会通过伙伴系统分配对应大小内存

![[Pasted image 20240316220758.png]]

![[Pasted image 20240316220805.png]]

# 参考

[Linux的内核空间（低端内存、高端内存](https://blog.csdn.net/qq_38410730/article/details/81105132)

[linux内存管理（详解） - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/149581303)