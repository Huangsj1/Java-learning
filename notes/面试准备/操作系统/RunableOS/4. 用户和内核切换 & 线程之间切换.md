# 一、用户和内核之间切换

## 1. 特权级指令和CSR寄存器

![[Pasted image 20240312113030.png|300]]![[Pasted image 20240312113039.png|300]]

接口：

* SBI 监督模式二进制接口：机器模式提供给监督模式的接口
* **ABI 应用程序二进制接口**：监督模式提供给用户模式的接口
* API 应用程序接口：应用程序之间的接口

特权级切换指令：

* `ecall`：从用户态切换到内核态（也可以从监督模式到机器模式）
	1. `sstatus`的 `SPP` 字段修改为当前特权级（U态调用就设置为U态）
	2. `sepc` 中保存程序计数器pc的值
	3. `scause & stval` 保存当前Trap的原因和附加信息
	4. 设置程序计数器pc为 `stvec` 的值（`trampoline`的地址值），更新cpu的mode标志位为supervisor表示进入监督模式
* `sret`：从内核态返回用户态
	1. `sstatus`的 `SPP` 字段修改为当前特权级（S态就设置为S态）
	2. 设置程序计数器pc的 `sepc` 寄存器的值（原本用户态的地址），更新cpu的mode标志位为user表示进入用户模式

CSR 控制和状态寄存器：

* `sepc`：U态进入S态时保存用户态pc值
* `stvec`：U态进入S态时pc跳转到的地址
	* 在OS初始化的时候就将 `__alltraps` 的地址写入
* `scause`：描述Trap的原因
* `stval`：Trap的附加信息
* `sstatus`：S态下当前线程的操作状态
	* `SPP`位：进入S态之前处理器权限级别
	* `SIE`位：S态下设置为0则无论发生什么中断处理器都不会响应（U态下一定会响应）
	* `SPIE`位：用来保存之前的 `SIE` 的值，为了防止中断嵌套（当U态trap到S态时，会将原本 `SIE`的1置到 `SPIE`中，然后将 `SIE`设置为0防止中断嵌套，但是S态可以被M态中断）
* `satp`：页表寄存器，保存根页表的物理页号

## 2. 用户态上下文

在调用 `ecall` 之后需要保存用户态上下文信息，包括寄存器、内核页表、内核栈地址等到 `TrapContext`中：

1. 包括32个通用寄存器：包括ra、sp等
2. CSR寄存器：`scause`和`stval`在进入trap时就使用了或是被保存了，但是`sstatus`和`sepc`在trap结束前还是会用到的且没被保存，所以需要手动保存
3. 由于需要从用户态切换到内核态，且只有一个 `sscratch` 寄存器能够用来保存内核态的信息（用来保存了 `TrapContext` 的地址给 `sp` 使用），所以剩下的跳转到内核态所需要用到的信息：**内核态根页表地址、内核栈地址、返回到内核态的处理函数的地址**也需要保存到 `TrapContext` 中

```rust
pub struct TrapContext {
	// 32个j基本寄存器
    pub x: [usize; 32],
    pub sstatus: Sstatus,
    pub sepc: usize,
    
    pub kernel_satp: usize,
    pub kernel_sp: usize,
    pub trap_handler: usize,
}
```

## 3. Trampoline中的切换

### 1. 用户 -> 内核

1. 进入时刻基本寄存器存储的还是在用户态下的内容（包括sp）
2. 通过 `csrrw` 交换用户栈 `sp` 和 `TrapContext` 的地址 `sscratch`，方便后面的保存
3. 在 `TranContext` 中保存需要保存的基本寄存器、CSR寄存器
4. 切换 `sp` 到内核栈
5. 切换 `satp` 到内核虚拟空间，刷新cpu地址缓存
6. 跳转到 `trap_handler` 处理程序

* `sp` 从 用户栈 -> `TrapContext` -> 内核栈

```asm
# os/src/trap/trap.S
# trampoline段
    .section .text.trampoline
    .globl __alltraps
    .globl __restore
    .align 2
# 陷入部分
__alltraps:
    csrrw sp, sscratch, sp
    # now sp->*TrapContext in user space, sscratch->user stack
    # save other general purpose registers
    sd x1, 1*8(sp)
    # skip sp(x2), we will save it later
    sd x3, 3*8(sp)
    # skip tp(x4), application does not use it
    # save x5~x31
    .set n, 5
    .rept 27
        SAVE_GP %n
        .set n, n+1
    .endr
    # we can use t0/t1/t2 freely, because they have been saved in TrapContext
    csrr t0, sstatus
    csrr t1, sepc
    sd t0, 32*8(sp)
    sd t1, 33*8(sp)
    # read user stack from sscratch and save it in TrapContext
    csrr t2, sscratch
    sd t2, 2*8(sp)
    # load kernel_satp into t0
    ld t0, 34*8(sp)
    # load trap_handler into t1
    ld t1, 36*8(sp)
    # move to kernel_sp
    ld sp, 35*8(sp)
    # switch to kernel space
    csrw satp, t0
    sfence.vma
    # jump to trap_handler
    jr t1
```

### 2. 内核 -> 用户

1. 切换 `satp` 回用户空间（为了后面读取之前在用户空间保存的信息），刷新cpu地址缓存
2. 将 `TrapContext` 地址放到 `sscratch` 中（使得下一次用户到内核可以读取出 `TrapContext` 地址）
3. 将 `TrapContext` 地址放到 `sp` 中，即当前使用的栈是 `TrapContext`
4. 读取出之前保存的所有用户态下的基本寄存器信息和 `sstatus & sepc` 寄存器
5. 切换回用户栈
6. `sret` 返回用户空间地址

* `sp` 从 内核栈 -> `TrapContext` -> 用户栈

```asm
# os/src/trap/trap.S
# 恢复部分
__restore:
    # a0: *TrapContext in user space(Constant); a1: user space token
    # switch to user space
    csrw satp, a1
    sfence.vma
    csrw sscratch, a0
    mv sp, a0
    # now sp points to TrapContext in user space, start restoring based on it
    # restore sstatus/sepc
    ld t0, 32*8(sp)
    ld t1, 33*8(sp)
    csrw sstatus, t0
    csrw sepc, t1
    # restore general purpose registers except x0/sp/tp
    ld x1, 1*8(sp)
    ld x3, 3*8(sp)
    .set n, 5
    .rept 27
        LOAD_GP %n
        .set n, n+1
    .endr
    # back to user stack
    ld sp, 2*8(sp)
    sret
```

# 二、系统调用

## 1. 函数调用过程

![[Pasted image 20240312110931.png|200]]

```asm
# 开场
# 为当前函数分配 64 字节的栈帧
addi        sp, sp, -64
# 将 ra 和 fp 压栈保存
sd  ra, 56(sp)
sd  s0, 48(sp)
# 更新 fp 为当前函数栈帧顶端地址
addi        s0, sp, 64

# 函数执行
# 中间如果再调用了其他函数会修改 ra

# 结尾
# 恢复 ra 和 fp
ld  ra, 56(sp)
ld  s0, 48(sp)
# 退栈
addi        sp, sp, 64
# 返回，使用 ret 指令或其他等价的实现方式
ret
```

# 三、线程之间切换

线程之间的切换是在**内核中**进行的

## 1. 线程上下文

`TaskContext` 记录了**当前内核线程的上下文**，包括返回地址 `ra`，内核栈 `sp`，需要自己保存的寄存器 `s`（其他寄存器在调用 `__switch`的时候就保存了，之后返回去的时候可以取出）

```rust
#[repr(C)]
pub struct TaskContext {
    ra: usize,
    sp: usize,
    s: [usize; 12],
}

impl TaskContext {
    pub fn zero_init() -> Self {
        Self {
            ra: 0,
            sp: 0,
            s: [0; 12],
        }
    }
    pub fn goto_trap_return(kstack_ptr: usize) -> Self {
        Self {
            ra: trap_return as usize,
            sp: kstack_ptr,
            s: [0; 12],
        }
    }
}
```

## 2. 线程切换

### 1. 切换的主要函数

1. 将当前cpu上下文保存到第一个参数中 `TaskContext current_tsak_cx_ptr`
	* **内核主线程**第一次执行切换 `run_tasks()` 的时候会保存当前cpu上下文到**处理器`Processor` 的 `idle_task_cx` 中**
	* **其他用户线程对应的内核线程**在进行切换 `schedule()` 的时候会保存当前cpu上下文到**线程的 `TCB` 中的 `task_cx` 中**
2. 将下一个需要运行的线程的 `TaskContex next_task_cx_ptr` 加载到cpu中
	* **内核主线程**第一次执行切换 `run_tasks()` 的时候会将选择下一个线程 `TCB` 来将其 `task_cx` 加载到cpu中
	* **其他用户线程对应的内核线程**在进行切换 `schedule()` 的时候会将处理器 `Processor` 中的 `idle_task_cx` 内核主线程上下文加载到cpu中，即回到了 `run_tasks()` 函数来进行下一个线程的加载

```asm
# os/src/task/switch.S

.altmacro
.macro SAVE_SN n
    sd s\n, (\n+2)*8(a0)
.endm
.macro LOAD_SN n
    ld s\n, (\n+2)*8(a1)
.endm
    .section .text
    .globl __switch
__switch:
    # __switch(
    #     current_task_cx_ptr: *mut TaskContext,
    #     next_task_cx_ptr: *const TaskContext
    # )
    # save kernel stack of current task
    sd sp, 8(a0)
    # save ra & s0~s11 of current execution
    sd ra, 0(a0)
    .set n, 0
    .rept 12
        SAVE_SN %n
        .set n, n + 1
    .endr
    # restore ra & s0~s11 of next execution
    ld ra, 0(a1)
    .set n, 0
    .rept 12
        LOAD_SN %n
        .set n, n + 1
    .endr
    # restore kernel stack of next task
    ld sp, 8(a1)
    ret
```

### 2. 内核主线程和用户的内核线程的上下文

```rust
// os/src/task/processor.rs
// 处理器中的主线程上下文
pub struct Processor {
    current: Option<Arc<TaskControlBlock>>,
    idle_task_cx: TaskContext,
}
```

```rust
// os/src/task/task.rs
// 用户的内核线程的上下文
pub struct TaskControlBlock {
    // immutable
    pub process: Weak<ProcessControlBlock>,
    pub kstack: KernelStack,
    // mutable
    inner: UPSafeCell<TaskControlBlockInner>,
}

pub struct TaskControlBlockInner {
    pub res: Option<TaskUserRes>,
    pub trap_cx_ppn: PhysPageNum,
    pub task_cx: TaskContext,
    pub task_status: TaskStatus,
    pub exit_code: Option<i32>,
}
```

执行切换的两个函数：

* `run_task()`：**内核主线程**执行，负责保存当前主线程cpu上下文信息到处理器 `Processor` 中，并选择下一个线程加载到 cpu 中执行
* `schedule()`：**其他用户的内核线程**执行，负责保存当前线程cpu上下文信息到`TCB`中，并切换回内核主线程到cpu中执行

```rust
// os/src/task/processor.rs
pub fn run_tasks() {
    loop {
        let mut processor = PROCESSOR.exclusive_access();
        if let Some(task) = fetch_task() {
            let idle_task_cx_ptr = processor.get_idle_task_cx_ptr();
            // access coming task TCB exclusively
            let mut task_inner = task.inner_exclusive_access();
            let next_task_cx_ptr = &task_inner.task_cx as *const TaskContext;
            task_inner.task_status = TaskStatus::Running;
            drop(task_inner);
            // release coming task TCB manually
            processor.current = Some(task);
            // release processor manually
            drop(processor);
            unsafe {
                __switch(idle_task_cx_ptr, next_task_cx_ptr);
            }
        } else {
            println!("no tasks available in run_tasks");
        }
    }
}

pub fn schedule(switched_task_cx_ptr: *mut TaskContext) {
    let mut processor = PROCESSOR.exclusive_access();
    let idle_task_cx_ptr = processor.get_idle_task_cx_ptr();
    drop(processor);
    unsafe {
        __switch(switched_task_cx_ptr, idle_task_cx_ptr);
    }
}
```

* 当用户程序执行完毕后，会一路从 `main()` 函数中返回到用户库的最后执行 `exit(main())`，然后通过系统调用结束在内核中执行 `exit_current_and_run_next` 结束当前线程，切换下一个线程

## 3. 创建子线程

用户可以通过系统调用 `thread_create(入口函数虚拟地址，入口函数参数)` 创建子线程，该子线程返回到用户态的时候**直接跳转到入口函数执行**，**结束后会调用 `exit()` 退出函数**

1. 在当前 `PCB` 下创建一个 `TCB`（会分配用户栈、内核栈、TrapContext等）
2. 将当前线程加入到等待队列中等待调度
3. 将 `TrapContext` 返回用户的地址改成入口函数地址

```rust
// os/src/syscall/thread.rs
pub fn sys_thread_create(entry: usize, arg: usize) -> isize {
    let task = current_task().unwrap();
    let process = task.process.upgrade().unwrap();
    // create a new thread
    let new_task = Arc::new(TaskControlBlock::new(
        Arc::clone(&process),
        true,
        None,
    ));
    // add new task to scheduler
    add_task(Arc::clone(&new_task));
    let new_task_inner = new_task.inner_exclusive_access();
    let new_task_res = new_task_inner.res.as_ref().unwrap();
    let new_task_tid = new_task_res.tid;
    let mut process_inner = process.inner_exclusive_access();
    // add new thread to current process
    let tasks = &mut process_inner.tasks;
    while tasks.len() < new_task_tid + 1 {
        tasks.push(None);
    }
    tasks[new_task_tid] = Some(Arc::clone(&new_task));
    let new_task_trap_cx = new_task_inner.get_trap_cx();
    *new_task_trap_cx = TrapContext::app_init_context(
        entry,
        new_task_res.ustack_top(),
        kernel_token(),
        new_task.kstack.get_top(),
        trap_handler as usize,
    );
    (*new_task_trap_cx).x[10] = arg;
    new_task_tid as isize
}
```